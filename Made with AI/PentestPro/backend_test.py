import requests
import sys
import json
from datetime import datetime
import time
import jwt

class PentestProAPITester:
    def __init__(self, base_url="https://vulntracker-13.preview.emergentagent.com"):
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
        self.tests_run = 0
        self.tests_passed = 0
        self.test_results = []
        self.auth_tokens = {}  # Store tokens for different users

    def run_test(self, name, method, endpoint, expected_status, data=None, description="", auth_token=None):
        """Run a single API test"""
        url = f"{self.api_url}/{endpoint}"
        headers = {'Content-Type': 'application/json'}
        
        # Add authorization header if token provided
        if auth_token:
            headers['Authorization'] = f'Bearer {auth_token}'

        self.tests_run += 1
        print(f"\nüîç Testing {name}...")
        print(f"   URL: {url}")
        if description:
            print(f"   Description: {description}")
        if auth_token:
            print(f"   Using authentication token")
        
        try:
            if method == 'GET':
                response = requests.get(url, headers=headers, timeout=10)
            elif method == 'POST':
                response = requests.post(url, json=data, headers=headers, timeout=10)
            elif method == 'PUT':
                response = requests.put(url, json=data, headers=headers, timeout=10)
            elif method == 'DELETE':
                response = requests.delete(url, headers=headers, timeout=10)

            success = response.status_code == expected_status
            if success:
                self.tests_passed += 1
                print(f"‚úÖ Passed - Status: {response.status_code}")
                try:
                    response_data = response.json() if response.content else {}
                    if isinstance(response_data, list):
                        print(f"   Response: List with {len(response_data)} items")
                    elif isinstance(response_data, dict):
                        print(f"   Response keys: {list(response_data.keys())}")
                except:
                    print(f"   Response: Non-JSON content")
            else:
                print(f"‚ùå Failed - Expected {expected_status}, got {response.status_code}")
                try:
                    error_content = response.json() if response.content else {}
                    print(f"   Error: {error_content}")
                except:
                    print(f"   Error content: {response.text[:200]}")

            self.test_results.append({
                "name": name,
                "method": method,
                "endpoint": endpoint,
                "expected_status": expected_status,
                "actual_status": response.status_code,
                "success": success,
                "description": description
            })

            return success, response.json() if success and response.content else {}

        except Exception as e:
            print(f"‚ùå Failed - Error: {str(e)}")
            self.test_results.append({
                "name": name,
                "method": method,
                "endpoint": endpoint,
                "expected_status": expected_status,
                "actual_status": "ERROR",
                "success": False,
                "error": str(e),
                "description": description
            })
            return False, {}

    def test_dashboard_endpoint(self):
        """Test dashboard data endpoint"""
        success, response = self.run_test(
            "Dashboard Data",
            "GET",
            "dashboard",
            200,
            description="Get dashboard statistics and recent assessments"
        )
        
        if success:
            required_keys = ['stats', 'recent_assessments']
            for key in required_keys:
                if key not in response:
                    print(f"‚ùå Missing required key: {key}")
                    return False
            
            stats = response.get('stats', {})
            required_stats = ['templates', 'assessments', 'completed', 'in_progress']
            for stat in required_stats:
                if stat not in stats:
                    print(f"‚ùå Missing stat: {stat}")
                    return False
            
            print(f"   Dashboard stats: {stats}")
        
        return success

    def test_templates_crud(self):
        """Test template CRUD operations"""
        # Test get all templates
        success, templates = self.run_test(
            "Get All Templates",
            "GET",
            "templates",
            200,
            description="Fetch all assessment templates"
        )
        
        if not success:
            return False
        
        print(f"   Found {len(templates)} templates")
        
        # Test get specific template if any exist
        if templates:
            template_id = templates[0]['id']
            success, template = self.run_test(
                "Get Specific Template",
                "GET",
                f"templates/{template_id}",
                200,
                description=f"Fetch template with ID: {template_id}"
            )
            
            if success:
                required_fields = ['id', 'name', 'description', 'category', 'steps']
                for field in required_fields:
                    if field not in template:
                        print(f"‚ùå Missing template field: {field}")
                        return False
                print(f"   Template: {template['name']} ({template['category']})")
        
        # Test create new template
        new_template_data = {
            "name": "Test Template",
            "description": "A test template for API testing",
            "category": "Testing",
            "steps": [
                {
                    "name": "Test Step",
                    "description": "A test step",
                    "instructions": "Follow these test instructions",
                    "fields": [
                        {
                            "label": "Test Field",
                            "type": "text",
                            "required": True
                        }
                    ],
                    "order": 1
                }
            ],
            "report_structure": [
                {
                    "title": "Test Section",
                    "content_template": "Test content template",
                    "order": 1
                }
            ]
        }
        
        success, created_template = self.run_test(
            "Create Template",
            "POST",
            "templates",
            200,
            data=new_template_data,
            description="Create a new assessment template"
        )
        
        if success:
            template_id = created_template['id']
            print(f"   Created template ID: {template_id}")
            
            # Test update template
            update_data = {
                "name": "Updated Test Template",
                "description": "Updated description"
            }
            
            success, updated_template = self.run_test(
                "Update Template",
                "PUT",
                f"templates/{template_id}",
                200,
                data=update_data,
                description="Update template name and description"
            )
            
            if success:
                print(f"   Updated template name: {updated_template['name']}")
            
            # Test delete template
            success, _ = self.run_test(
                "Delete Template",
                "DELETE",
                f"templates/{template_id}",
                200,
                description="Delete the test template"
            )
            
            if success:
                print(f"   Deleted template ID: {template_id}")
        
        return True

    def test_assessments_crud(self):
        """Test assessment CRUD operations"""
        # First get templates to use for assessment creation
        success, templates = self.run_test(
            "Get Templates for Assessment",
            "GET",
            "templates",
            200,
            description="Get templates to create assessment"
        )
        
        if not success or not templates:
            print("‚ùå No templates available for assessment testing")
            return False
        
        template_id = templates[0]['id']
        
        # Test get all assessments
        success, assessments = self.run_test(
            "Get All Assessments",
            "GET",
            "assessments",
            200,
            description="Fetch all assessments"
        )
        
        if not success:
            return False
        
        print(f"   Found {len(assessments)} assessments")
        
        # Test create new assessment
        new_assessment_data = {
            "template_id": template_id,
            "name": "Test Assessment"
        }
        
        success, created_assessment = self.run_test(
            "Create Assessment",
            "POST",
            "assessments",
            200,
            data=new_assessment_data,
            description="Create a new assessment"
        )
        
        if success:
            assessment_id = created_assessment['id']
            print(f"   Created assessment ID: {assessment_id}")
            
            # Test get specific assessment
            success, assessment = self.run_test(
                "Get Specific Assessment",
                "GET",
                f"assessments/{assessment_id}",
                200,
                description=f"Fetch assessment with ID: {assessment_id}"
            )
            
            if success:
                required_fields = ['id', 'template_id', 'name', 'status', 'data', 'current_step']
                for field in required_fields:
                    if field not in assessment:
                        print(f"‚ùå Missing assessment field: {field}")
                        return False
                print(f"   Assessment: {assessment['name']} (Status: {assessment['status']})")
            
            # Test update assessment
            update_data = {
                "status": "in_progress",
                "current_step": 1,
                "data": {
                    "step_1": {
                        "test_field": "test_value"
                    }
                }
            }
            
            success, updated_assessment = self.run_test(
                "Update Assessment",
                "PUT",
                f"assessments/{assessment_id}",
                200,
                data=update_data,
                description="Update assessment status and data"
            )
            
            if success:
                print(f"   Updated assessment status: {updated_assessment['status']}")
            
            # Test report generation
            success, report = self.run_test(
                "Generate Report",
                "POST",
                f"assessments/{assessment_id}/report",
                200,
                description="Generate report for assessment"
            )
            
            if success:
                print(f"   Generated report ID: {report['id']}")
                
                # Test get assessment reports
                success, reports = self.run_test(
                    "Get Assessment Reports",
                    "GET",
                    f"assessments/{assessment_id}/reports",
                    200,
                    description="Get all reports for assessment"
                )
                
                if success:
                    print(f"   Found {len(reports)} reports for assessment")
            
            # Test delete assessment
            success, _ = self.run_test(
                "Delete Assessment",
                "DELETE",
                f"assessments/{assessment_id}",
                200,
                description="Delete the test assessment"
            )
            
            if success:
                print(f"   Deleted assessment ID: {assessment_id}")
        
        return True

    def test_sample_data_initialization(self):
        """Test sample data initialization"""
        success, response = self.run_test(
            "Initialize Sample Data",
            "POST",
            "init-sample-data",
            200,
            description="Initialize sample templates and data"
        )
        
        if success:
            print(f"   Sample data response: {response}")
        
        return success

    def test_expanded_templates_functionality(self):
        """Test the 8 expanded templates functionality specifically"""
        print("\nüîç Testing Expanded Templates Functionality...")
        
        # Expected expanded templates with their step counts
        expanded_templates = {
            "Blockchain & Smart Contract Security": 6,
            "Supply Chain Security Assessment": 5, 
            "Email Security Assessment": 6,
            "DNS Security Assessment": 6,
            "Zero Trust Architecture Assessment": 7,
            "Compliance Assessment (PCI DSS / HIPAA / SOC2)": 6,
            "Source Code Security Review": 6,
            "Wireless Network Security Assessment": 6
        }
        
        # First, get all templates
        success, templates = self.run_test(
            "Get All Templates for Expansion Check",
            "GET",
            "templates",
            200,
            description="Fetch all templates to verify expanded ones"
        )
        
        if not success:
            print("‚ùå Failed to get templates for expansion testing")
            return False
        
        print(f"   Total templates found: {len(templates)}")
        
        # Check if we have at least 25 templates as expected
        if len(templates) < 25:
            print(f"‚ùå Expected at least 25 templates, found {len(templates)}")
            return False
        else:
            print(f"‚úÖ Template count check passed: {len(templates)} templates")
        
        # Find and test each expanded template
        expanded_found = {}
        all_expanded_tests_passed = True
        
        for template in templates:
            template_name = template.get('name', '')
            if template_name in expanded_templates:
                expanded_found[template_name] = template
                expected_steps = expanded_templates[template_name]
                
                print(f"\n   üîç Testing expanded template: {template_name}")
                
                # Test template retrieval by ID
                template_id = template['id']
                success, detailed_template = self.run_test(
                    f"Get Expanded Template: {template_name}",
                    "GET",
                    f"templates/{template_id}",
                    200,
                    description=f"Fetch detailed {template_name} template"
                )
                
                if not success:
                    print(f"‚ùå Failed to get detailed template for {template_name}")
                    all_expanded_tests_passed = False
                    continue
                
                # Verify step count
                actual_steps = len(detailed_template.get('steps', []))
                if actual_steps != expected_steps:
                    print(f"‚ùå {template_name}: Expected {expected_steps} steps, found {actual_steps}")
                    all_expanded_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Step count correct ({actual_steps} steps)")
                
                # Verify comprehensive fields in steps
                total_fields = 0
                field_types_found = set()
                
                for i, step in enumerate(detailed_template.get('steps', []), 1):
                    step_fields = step.get('fields', [])
                    total_fields += len(step_fields)
                    
                    for field in step_fields:
                        field_types_found.add(field.get('type', ''))
                    
                    print(f"      Step {i}: {step.get('name', 'Unknown')} - {len(step_fields)} fields")
                
                print(f"      Total fields: {total_fields}")
                print(f"      Field types used: {sorted(field_types_found)}")
                
                # Verify comprehensive report structure
                report_sections = detailed_template.get('report_structure', [])
                if len(report_sections) < 4:  # Expanded templates should have more sections
                    print(f"‚ùå {template_name}: Expected comprehensive report structure, found {len(report_sections)} sections")
                    all_expanded_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Report structure comprehensive ({len(report_sections)} sections)")
                
                # Verify field diversity (should have multiple field types)
                if len(field_types_found) < 3:
                    print(f"‚ùå {template_name}: Limited field type diversity ({len(field_types_found)} types)")
                    all_expanded_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Good field type diversity ({len(field_types_found)} types)")
        
        # Check if all expected expanded templates were found
        missing_templates = set(expanded_templates.keys()) - set(expanded_found.keys())
        if missing_templates:
            print(f"‚ùå Missing expanded templates: {missing_templates}")
            all_expanded_tests_passed = False
        else:
            print(f"‚úÖ All 8 expanded templates found and verified")
        
        return all_expanded_tests_passed
    
    def test_template_creation_workflow(self):
        """Test template creation workflow with comprehensive data"""
        print("\nüîç Testing Template Creation Workflow...")
        
        # Create a comprehensive template similar to expanded ones
        comprehensive_template_data = {
            "name": "Test Comprehensive Security Assessment",
            "description": "A comprehensive security assessment template for testing expanded functionality",
            "category": "Testing",
            "steps": [
                {
                    "name": "Initial Assessment",
                    "description": "Comprehensive initial security assessment",
                    "instructions": "Conduct thorough initial assessment following industry standards",
                    "fields": [
                        {
                            "label": "Target System URL",
                            "type": "url",
                            "required": True,
                            "placeholder": "https://example.com"
                        },
                        {
                            "label": "Assessment Type",
                            "type": "select",
                            "required": True,
                            "options": ["Internal", "External", "Hybrid"]
                        },
                        {
                            "label": "Scope Description",
                            "type": "textarea",
                            "required": True,
                            "placeholder": "Detailed scope description"
                        },
                        {
                            "label": "Critical Systems Count",
                            "type": "number",
                            "required": False
                        },
                        {
                            "label": "Compliance Required",
                            "type": "checkbox",
                            "required": False
                        }
                    ],
                    "order": 1
                },
                {
                    "name": "Vulnerability Assessment",
                    "description": "Comprehensive vulnerability identification and analysis",
                    "instructions": "Perform detailed vulnerability assessment using multiple tools and techniques",
                    "fields": [
                        {
                            "label": "Scanning Tools Used",
                            "type": "textarea",
                            "required": True,
                            "placeholder": "List all scanning tools and versions"
                        },
                        {
                            "label": "Critical Vulnerabilities",
                            "type": "number",
                            "required": True
                        },
                        {
                            "label": "High Risk Vulnerabilities",
                            "type": "number",
                            "required": True
                        },
                        {
                            "label": "Vulnerability Categories",
                            "type": "select",
                            "options": ["Injection", "Authentication", "Encryption", "Configuration", "Other"]
                        }
                    ],
                    "order": 2
                },
                {
                    "name": "Risk Analysis",
                    "description": "Comprehensive risk analysis and impact assessment",
                    "instructions": "Analyze identified vulnerabilities and assess business impact",
                    "fields": [
                        {
                            "label": "Business Impact Assessment",
                            "type": "textarea",
                            "required": True,
                            "placeholder": "Detailed business impact analysis"
                        },
                        {
                            "label": "Risk Rating",
                            "type": "select",
                            "required": True,
                            "options": ["Critical", "High", "Medium", "Low"]
                        },
                        {
                            "label": "Exploitability Score",
                            "type": "number",
                            "required": False
                        }
                    ],
                    "order": 3
                }
            ],
            "report_structure": [
                {
                    "title": "Executive Summary",
                    "content_template": "High-level overview of security assessment findings and business impact",
                    "order": 1
                },
                {
                    "title": "Assessment Methodology",
                    "content_template": "Detailed methodology and approach used for the security assessment",
                    "order": 2
                },
                {
                    "title": "Technical Findings",
                    "content_template": "Detailed technical vulnerabilities with proof-of-concept and remediation guidance",
                    "order": 3
                },
                {
                    "title": "Risk Assessment",
                    "content_template": "Comprehensive risk analysis with business impact assessment",
                    "order": 4
                },
                {
                    "title": "Remediation Roadmap",
                    "content_template": "Prioritized remediation plan with timelines and implementation guidance",
                    "order": 5
                },
                {
                    "title": "Compliance Analysis",
                    "content_template": "Analysis against relevant compliance frameworks and standards",
                    "order": 6
                },
                {
                    "title": "Appendices",
                    "content_template": "Supporting documentation, tool outputs, and detailed technical data",
                    "order": 7
                }
            ]
        }
        
        # Test creating the comprehensive template
        success, created_template = self.run_test(
            "Create Comprehensive Template",
            "POST",
            "templates",
            200,
            data=comprehensive_template_data,
            description="Create a comprehensive template with multiple steps and field types"
        )
        
        if not success:
            print("‚ùå Failed to create comprehensive template")
            return False
        
        template_id = created_template['id']
        print(f"‚úÖ Created comprehensive template ID: {template_id}")
        
        # Verify the created template has all expected components
        success, detailed_template = self.run_test(
            "Verify Created Comprehensive Template",
            "GET",
            f"templates/{template_id}",
            200,
            description="Verify comprehensive template was created correctly"
        )
        
        if success:
            steps = detailed_template.get('steps', [])
            report_sections = detailed_template.get('report_structure', [])
            
            print(f"   Steps created: {len(steps)}")
            print(f"   Report sections created: {len(report_sections)}")
            
            # Count total fields and field types
            total_fields = sum(len(step.get('fields', [])) for step in steps)
            field_types = set()
            for step in steps:
                for field in step.get('fields', []):
                    field_types.add(field.get('type', ''))
            
            print(f"   Total fields: {total_fields}")
            print(f"   Field types: {sorted(field_types)}")
            
            # Clean up - delete the test template
            success, _ = self.run_test(
                "Delete Test Comprehensive Template",
                "DELETE",
                f"templates/{template_id}",
                200,
                description="Clean up test template"
            )
            
            if success:
                print(f"‚úÖ Cleaned up test template ID: {template_id}")
        
        return success
    
    def test_dashboard_template_statistics(self):
        """Test dashboard statistics specifically for template counts"""
        print("\nüîç Testing Dashboard Template Statistics...")
        
        success, dashboard_data = self.run_test(
            "Get Dashboard Statistics",
            "GET",
            "dashboard",
            200,
            description="Get dashboard data to verify template statistics"
        )
        
        if not success:
            print("‚ùå Failed to get dashboard statistics")
            return False
        
        stats = dashboard_data.get('stats', {})
        template_count = stats.get('templates', 0)
        
        print(f"   Dashboard reports {template_count} templates")
        
        # Cross-verify with direct template count
        success, templates = self.run_test(
            "Cross-verify Template Count",
            "GET",
            "templates",
            200,
            description="Get all templates to cross-verify count"
        )
        
        if success:
            actual_count = len(templates)
            print(f"   Direct count shows {actual_count} templates")
            
            if template_count == actual_count:
                print(f"‚úÖ Dashboard template count matches actual count: {template_count}")
                return True
            else:
                print(f"‚ùå Dashboard count ({template_count}) doesn't match actual count ({actual_count})")
                return False
        
        return False

    def test_error_handling(self):
        """Test error handling for invalid requests"""
        # Test non-existent template
        success, _ = self.run_test(
            "Get Non-existent Template",
            "GET",
            "templates/non-existent-id",
            404,
            description="Test 404 error for non-existent template"
        )
        
        # Test non-existent assessment
        success2, _ = self.run_test(
            "Get Non-existent Assessment",
            "GET",
            "assessments/non-existent-id",
            404,
            description="Test 404 error for non-existent assessment"
        )
        
        # Test invalid assessment creation (missing template_id)
        success3, _ = self.run_test(
            "Create Invalid Assessment",
            "POST",
            "assessments",
            422,  # Validation error
            data={"name": "Test"},
            description="Test validation error for missing template_id"
        )
        
        return success and success2

    def test_newly_expanded_templates(self):
        """Test the 3 newly expanded templates specifically mentioned in review request"""
        print("\nüîç Testing Newly Expanded Templates (Compliance, Source Code, Wireless)...")
        
        # The 3 newly expanded templates with expected specifications
        newly_expanded_templates = {
            "Compliance Assessment (PCI DSS / HIPAA / SOC2)": {
                "expected_steps": 6,
                "expected_min_fields": 60,
                "expected_min_sections": 7,
                "description": "expanded from 2 steps to 6 comprehensive steps"
            },
            "Source Code Security Review": {
                "expected_steps": 6,
                "expected_min_fields": 60,
                "expected_min_sections": 8,
                "description": "expanded from 2 steps to 6 comprehensive steps"
            },
            "Wireless Network Security Assessment": {
                "expected_steps": 6,
                "expected_min_fields": 60,
                "expected_min_sections": 8,
                "description": "expanded from 3 steps to 6 comprehensive steps"
            }
        }
        
        # First, get all templates
        success, templates = self.run_test(
            "Get All Templates for New Expansion Check",
            "GET",
            "templates",
            200,
            description="Fetch all templates to verify newly expanded ones"
        )
        
        if not success:
            print("‚ùå Failed to get templates for new expansion testing")
            return False
        
        print(f"   Total templates found: {len(templates)}")
        
        # Find and test each newly expanded template
        newly_expanded_found = {}
        all_tests_passed = True
        
        for template in templates:
            template_name = template.get('name', '')
            if template_name in newly_expanded_templates:
                newly_expanded_found[template_name] = template
                expected_config = newly_expanded_templates[template_name]
                
                print(f"\n   üîç Testing newly expanded template: {template_name}")
                print(f"      Expected: {expected_config['description']}")
                
                # Test template retrieval by ID
                template_id = template['id']
                success, detailed_template = self.run_test(
                    f"Get Newly Expanded Template: {template_name}",
                    "GET",
                    f"templates/{template_id}",
                    200,
                    description=f"Fetch detailed {template_name} template"
                )
                
                if not success:
                    print(f"‚ùå Failed to get detailed template for {template_name}")
                    all_tests_passed = False
                    continue
                
                # Verify step count (should be 6 for all newly expanded)
                actual_steps = len(detailed_template.get('steps', []))
                expected_steps = expected_config['expected_steps']
                if actual_steps != expected_steps:
                    print(f"‚ùå {template_name}: Expected {expected_steps} steps, found {actual_steps}")
                    all_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Step count correct ({actual_steps} steps)")
                
                # Verify comprehensive fields in steps (should be 60+ fields each)
                total_fields = 0
                field_types_found = set()
                
                for i, step in enumerate(detailed_template.get('steps', []), 1):
                    step_fields = step.get('fields', [])
                    total_fields += len(step_fields)
                    
                    for field in step_fields:
                        field_types_found.add(field.get('type', ''))
                    
                    print(f"      Step {i}: {step.get('name', 'Unknown')} - {len(step_fields)} fields")
                
                expected_min_fields = expected_config['expected_min_fields']
                if total_fields < expected_min_fields:
                    print(f"‚ùå {template_name}: Expected {expected_min_fields}+ fields, found {total_fields}")
                    all_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Field count meets requirement ({total_fields} fields)")
                
                print(f"      Field types used: {sorted(field_types_found)}")
                
                # Verify comprehensive report structure (7-8 sections)
                report_sections = detailed_template.get('report_structure', [])
                expected_min_sections = expected_config['expected_min_sections']
                if len(report_sections) < expected_min_sections:
                    print(f"‚ùå {template_name}: Expected {expected_min_sections}+ sections, found {len(report_sections)}")
                    all_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Report structure comprehensive ({len(report_sections)} sections)")
                
                # Verify field diversity (should have multiple field types)
                if len(field_types_found) < 3:
                    print(f"‚ùå {template_name}: Limited field type diversity ({len(field_types_found)} types)")
                    all_tests_passed = False
                else:
                    print(f"‚úÖ {template_name}: Good field type diversity ({len(field_types_found)} types)")
                
                # Test API performance - template should load without timeout
                print(f"      API performance: Template loaded successfully without timeout")
        
        # Check if all expected newly expanded templates were found
        missing_templates = set(newly_expanded_templates.keys()) - set(newly_expanded_found.keys())
        if missing_templates:
            print(f"‚ùå Missing newly expanded templates: {missing_templates}")
            all_tests_passed = False
        else:
            print(f"‚úÖ All 3 newly expanded templates found and verified")
        
        # Summary of newly expanded templates
        if all_tests_passed:
            print(f"\n‚úÖ NEWLY EXPANDED TEMPLATES VALIDATION COMPLETE:")
    def test_user_registration(self):
        """Test user registration functionality"""
        print("\nüîç Testing User Registration...")
        
        # Test data for different user roles
        test_users = [
            {
                "email": "admin@pentestpro.com",
                "username": "admin_user",
                "password": "AdminPass123!",
                "full_name": "Admin User",
                "role": "admin",
                "organization": "PentestPro Corp",
                "team": "Security Team"
            },
            {
                "email": "analyst@pentestpro.com", 
                "username": "security_analyst",
                "password": "AnalystPass123!",
                "full_name": "Security Analyst",
                "role": "security_analyst",
                "organization": "PentestPro Corp"
            },
            {
                "email": "viewer@pentestpro.com",
                "username": "viewer_user", 
                "password": "ViewerPass123!",
                "full_name": "Viewer User",
                "role": "viewer"
            },
            {
                "email": "auditor@pentestpro.com",
                "username": "auditor_user",
                "password": "AuditorPass123!",
                "full_name": "Auditor User", 
                "role": "auditor"
            }
        ]
        
        all_tests_passed = True
        
        for user_data in test_users:
            role = user_data["role"]
            print(f"\n   üîç Testing registration for {role} role...")
            
            # Test successful registration
            success, response = self.run_test(
                f"Register {role.title()} User",
                "POST",
                "auth/register",
                200,
                data=user_data,
                description=f"Register new {role} user with valid data"
            )
            
            if success:
                # Verify response structure
                required_keys = ['access_token', 'token_type', 'expires_in', 'user']
                for key in required_keys:
                    if key not in response:
                        print(f"‚ùå Missing key in registration response: {key}")
                        all_tests_passed = False
                        continue
                
                # Verify user data (password should not be returned)
                user = response.get('user', {})
                if 'password' in user or 'password_hash' in user:
                    print(f"‚ùå Password exposed in registration response")
                    all_tests_passed = False
                
                # Verify JWT token structure
                token = response.get('access_token')
                if token:
                    try:
                        # Decode without verification to check structure
                        decoded = jwt.decode(token, options={"verify_signature": False})
                        if 'sub' not in decoded or 'exp' not in decoded:
                            print(f"‚ùå Invalid JWT token structure")
                            all_tests_passed = False
                        else:
                            print(f"   ‚úÖ JWT token structure valid")
                            # Store token for later tests
                            self.auth_tokens[role] = token
                    except Exception as e:
                        print(f"‚ùå JWT token decode error: {e}")
                        all_tests_passed = False
                
                print(f"   ‚úÖ {role.title()} user registered successfully")
                print(f"   User ID: {user.get('id')}")
                print(f"   Email: {user.get('email')}")
                print(f"   Role: {user.get('role')}")
            else:
                all_tests_passed = False
        
        # Test duplicate email registration
        duplicate_user = {
            "email": "admin@pentestpro.com",  # Same as first user
            "username": "admin_duplicate",
            "password": "DuplicatePass123!",
            "full_name": "Duplicate Admin",
            "role": "admin"
        }
        
        success, response = self.run_test(
            "Register Duplicate Email",
            "POST", 
            "auth/register",
            400,
            data=duplicate_user,
            description="Test duplicate email validation"
        )
        
        if success:
            print("   ‚úÖ Duplicate email properly rejected")
        else:
            all_tests_passed = False
        
        # Test duplicate username registration
        duplicate_username = {
            "email": "admin2@pentestpro.com",
            "username": "admin_user",  # Same as first user
            "password": "DuplicatePass123!",
            "full_name": "Duplicate Username",
            "role": "admin"
        }
        
        success, response = self.run_test(
            "Register Duplicate Username",
            "POST",
            "auth/register", 
            400,
            data=duplicate_username,
            description="Test duplicate username validation"
        )
        
        if success:
            print("   ‚úÖ Duplicate username properly rejected")
        else:
            all_tests_passed = False
        
        return all_tests_passed

    def test_user_login(self):
        """Test user login functionality"""
        print("\nüîç Testing User Login...")
        
        # Test valid login credentials
        login_tests = [
            {
                "email": "admin@pentestpro.com",
                "password": "AdminPass123!",
                "role": "admin"
            },
            {
                "email": "analyst@pentestpro.com", 
                "password": "AnalystPass123!",
                "role": "security_analyst"
            }
        ]
        
        all_tests_passed = True
        
        for login_data in login_tests:
            role = login_data["role"]
            print(f"\n   üîç Testing login for {role}...")
            
            success, response = self.run_test(
                f"Login {role.title()} User",
                "POST",
                "auth/login",
                200,
                data={"email": login_data["email"], "password": login_data["password"]},
                description=f"Login with valid {role} credentials"
            )
            
            if success:
                # Verify response structure
                required_keys = ['access_token', 'token_type', 'expires_in', 'user']
                for key in required_keys:
                    if key not in response:
                        print(f"‚ùå Missing key in login response: {key}")
                        all_tests_passed = False
                        continue
                
                # Verify token expiration (should be 30 days = 43200 minutes)
                expires_in = response.get('expires_in')
                expected_expiry = 30 * 24 * 60  # 30 days in minutes
                if expires_in != expected_expiry:
                    print(f"‚ùå Incorrect token expiration: expected {expected_expiry}, got {expires_in}")
                    all_tests_passed = False
                else:
                    print(f"   ‚úÖ Token expiration correct: {expires_in} minutes (30 days)")
                
                # Update stored token
                token = response.get('access_token')
                if token:
                    self.auth_tokens[role] = token
                    print(f"   ‚úÖ {role.title()} login successful")
            else:
                all_tests_passed = False
        
        # Test invalid email
        success, response = self.run_test(
            "Login Invalid Email",
            "POST",
            "auth/login",
            401,
            data={"email": "nonexistent@pentestpro.com", "password": "SomePassword123!"},
            description="Test login with invalid email"
        )
        
        if success:
            print("   ‚úÖ Invalid email properly rejected")
        else:
            all_tests_passed = False
        
        # Test invalid password
        success, response = self.run_test(
            "Login Invalid Password",
            "POST", 
            "auth/login",
            401,
            data={"email": "admin@pentestpro.com", "password": "WrongPassword123!"},
            description="Test login with invalid password"
        )
        
        if success:
            print("   ‚úÖ Invalid password properly rejected")
        else:
            all_tests_passed = False
        
        return all_tests_passed

    def test_protected_endpoints(self):
        """Test protected endpoints with JWT authentication"""
        print("\nüîç Testing Protected Endpoints...")
        
        all_tests_passed = True
        
        # Test /api/auth/me with valid token
        if 'admin' in self.auth_tokens:
            admin_token = self.auth_tokens['admin']
            
            success, response = self.run_test(
                "Get Current User Info (Valid Token)",
                "GET",
                "auth/me",
                200,
                auth_token=admin_token,
                description="Get current user info with valid JWT token"
            )
            
            if success:
                # Verify user data structure
                required_fields = ['id', 'email', 'username', 'full_name', 'role', 'settings']
                for field in required_fields:
                    if field not in response:
                        print(f"‚ùå Missing user field: {field}")
                        all_tests_passed = False
                
                # Verify no password data exposed
                if 'password' in response or 'password_hash' in response:
                    print(f"‚ùå Password data exposed in user info")
                    all_tests_passed = False
                
                print(f"   ‚úÖ User info retrieved successfully")
                print(f"   User: {response.get('full_name')} ({response.get('role')})")
            else:
                all_tests_passed = False
        
        # Test /api/auth/me without token (should return 401)
        success, response = self.run_test(
            "Get Current User Info (No Token)",
            "GET",
            "auth/me", 
            401,
            description="Test protected endpoint without authentication token"
        )
        
        if success:
            print("   ‚úÖ Unauthorized access properly rejected")
        else:
            all_tests_passed = False
        
        # Test /api/auth/me with invalid token
        success, response = self.run_test(
            "Get Current User Info (Invalid Token)",
            "GET",
            "auth/me",
            401,
            auth_token="invalid.jwt.token",
            description="Test protected endpoint with invalid token"
        )
        
        if success:
            print("   ‚úÖ Invalid token properly rejected")
        else:
            all_tests_passed = False
        
        return all_tests_passed

    def test_role_based_permissions(self):
        """Test role-based permissions system"""
        print("\nüîç Testing Role-Based Permissions...")
        
        all_tests_passed = True
        
        # Test permissions for different roles
        role_permission_tests = [
            {
                "role": "admin",
                "expected_permissions": {
                    "can_create_assessments": True,
                    "can_edit_assessments": True,
                    "can_delete_assessments": True,
                    "can_view_all_assessments": True,
                    "can_create_templates": True,
                    "can_edit_templates": True,
                    "can_delete_templates": True,
                    "can_manage_users": True,
                    "can_view_reports": True,
                    "can_generate_reports": True,
                    "can_delete_reports": True
                }
            },
            {
                "role": "security_analyst",
                "expected_permissions": {
                    "can_create_assessments": True,
                    "can_edit_assessments": True,
                    "can_delete_assessments": False,
                    "can_view_all_assessments": False,
                    "can_create_templates": False,
                    "can_edit_templates": False,
                    "can_delete_templates": False,
                    "can_manage_users": False,
                    "can_view_reports": True,
                    "can_generate_reports": True,
                    "can_delete_reports": False
                }
            },
            {
                "role": "viewer",
                "expected_permissions": {
                    "can_create_assessments": False,
                    "can_edit_assessments": False,
                    "can_delete_assessments": False,
                    "can_view_all_assessments": False,
                    "can_create_templates": False,
                    "can_edit_templates": False,
                    "can_delete_templates": False,
                    "can_manage_users": False,
                    "can_view_reports": True,
                    "can_generate_reports": False,
                    "can_delete_reports": False
                }
            },
            {
                "role": "auditor",
                "expected_permissions": {
                    "can_create_assessments": True,
                    "can_edit_assessments": True,
                    "can_delete_assessments": False,
                    "can_view_all_assessments": True,
                    "can_create_templates": False,
                    "can_edit_templates": False,
                    "can_delete_templates": False,
                    "can_manage_users": False,
                    "can_view_reports": True,
                    "can_generate_reports": True,
                    "can_delete_reports": False
                }
            }
        ]
        
        for test_case in role_permission_tests:
            role = test_case["role"]
            expected_perms = test_case["expected_permissions"]
            
            if role in self.auth_tokens:
                token = self.auth_tokens[role]
                
                print(f"\n   üîç Testing permissions for {role}...")
                
                success, response = self.run_test(
                    f"Get {role.title()} Permissions",
                    "GET",
                    "auth/permissions",
                    200,
                    auth_token=token,
                    description=f"Get permissions for {role} role"
                )
                
                if success:
                    # Verify each expected permission
                    permissions_correct = True
                    for perm_name, expected_value in expected_perms.items():
                        actual_value = response.get(perm_name)
                        if actual_value != expected_value:
                            print(f"‚ùå {role} {perm_name}: expected {expected_value}, got {actual_value}")
                            permissions_correct = False
                            all_tests_passed = False
                    
                    if permissions_correct:
                        print(f"   ‚úÖ {role.title()} permissions correct")
                        print(f"   Key permissions: create_assessments={response.get('can_create_assessments')}, manage_users={response.get('can_manage_users')}, view_all={response.get('can_view_all_assessments')}")
                else:
                    all_tests_passed = False
        
        return all_tests_passed

    def test_user_settings(self):
        """Test user settings management"""
        print("\nüîç Testing User Settings Management...")
        
        all_tests_passed = True
        
        if 'admin' in self.auth_tokens:
            admin_token = self.auth_tokens['admin']
            
            # Test get user settings
            success, response = self.run_test(
                "Get User Settings",
                "GET",
                "user/settings",
                200,
                auth_token=admin_token,
                description="Get current user settings"
            )
            
            if success:
                # Verify settings structure
                expected_settings = ['theme', 'notifications_enabled', 'email_notifications', 
                                   'dashboard_layout', 'report_auto_generate', 'reports_per_page']
                for setting in expected_settings:
                    if setting not in response:
                        print(f"‚ùå Missing setting: {setting}")
                        all_tests_passed = False
                
                print(f"   ‚úÖ User settings retrieved successfully")
                print(f"   Current theme: {response.get('theme')}")
                print(f"   Notifications: {response.get('notifications_enabled')}")
            else:
                all_tests_passed = False
            
            # Test update user settings
            settings_updates = [
                {
                    "theme": "dark",
                    "notifications_enabled": False,
                    "dashboard_layout": "compact"
                },
                {
                    "theme": "light",
                    "email_notifications": True,
                    "reports_per_page": 25
                },
                {
                    "theme": "high_contrast",
                    "report_auto_generate": True
                }
            ]
            
            for i, update_data in enumerate(settings_updates, 1):
                success, response = self.run_test(
                    f"Update User Settings {i}",
                    "PUT",
                    "user/settings",
                    200,
                    data=update_data,
                    auth_token=admin_token,
                    description=f"Update user settings - test {i}"
                )
                
                if success:
                    # Verify updates were applied
                    for key, expected_value in update_data.items():
                        actual_value = response.get(key)
                        if actual_value != expected_value:
                            print(f"‚ùå Setting {key}: expected {expected_value}, got {actual_value}")
                            all_tests_passed = False
                    
                    print(f"   ‚úÖ Settings update {i} successful")
                else:
                    all_tests_passed = False
        
        # Test settings without authentication
        success, response = self.run_test(
            "Get Settings (No Auth)",
            "GET",
            "user/settings",
            401,
            description="Test settings endpoint without authentication"
        )
        
        if success:
            print("   ‚úÖ Unauthorized settings access properly rejected")
        else:
            all_tests_passed = False
        
        return all_tests_passed

    def test_profile_management(self):
        """Test user profile management"""
        print("\nüîç Testing Profile Management...")
        
        all_tests_passed = True
        
        if 'admin' in self.auth_tokens:
            admin_token = self.auth_tokens['admin']
            
            # Test profile update
            profile_updates = [
                {
                    "full_name": "Updated Admin User",
                    "organization": "Updated PentestPro Corp",
                    "team": "Updated Security Team"
                },
                {
                    "username": "updated_admin",
                    "avatar_url": "https://example.com/avatar.jpg"
                }
            ]
            
            for i, update_data in enumerate(profile_updates, 1):
                success, response = self.run_test(
                    f"Update User Profile {i}",
                    "PUT",
                    "auth/me",
                    200,
                    data=update_data,
                    auth_token=admin_token,
                    description=f"Update user profile - test {i}"
                )
                
                if success:
                    # Verify updates were applied
                    for key, expected_value in update_data.items():
                        actual_value = response.get(key)
                        if actual_value != expected_value:
                            print(f"‚ùå Profile {key}: expected {expected_value}, got {actual_value}")
                            all_tests_passed = False
                    
                    print(f"   ‚úÖ Profile update {i} successful")
                    print(f"   Updated: {', '.join(update_data.keys())}")
                else:
                    all_tests_passed = False
        
        return all_tests_passed

    def test_authentication_comprehensive(self):
        """Run comprehensive authentication system tests"""
        print("\nüöÄ Starting Comprehensive Authentication System Testing...")
        print("=" * 80)
        
        all_tests_passed = True
        
        # Run all authentication tests in sequence
        test_methods = [
            ("User Registration", self.test_user_registration),
            ("User Login", self.test_user_login), 
            ("Protected Endpoints", self.test_protected_endpoints),
            ("Role-Based Permissions", self.test_role_based_permissions),
            ("User Settings", self.test_user_settings),
            ("Profile Management", self.test_profile_management)
        ]
        
        for test_name, test_method in test_methods:
            print(f"\n{'='*20} {test_name} {'='*20}")
            try:
                result = test_method()
                if not result:
                    all_tests_passed = False
                    print(f"‚ùå {test_name} tests failed")
                else:
                    print(f"‚úÖ {test_name} tests passed")
            except Exception as e:
                print(f"‚ùå {test_name} tests error: {e}")
                all_tests_passed = False
        
        return all_tests_passed

def main():
    print("üöÄ Starting PentestPro API Testing - Authentication System Focus...")
    print("=" * 80)
    
    tester = PentestProAPITester()
    
    # Run comprehensive authentication system tests
    print("\nüîê Testing Authentication System...")
    auth_result = tester.test_authentication_comprehensive()
    
    # Print final results
    print("\n" + "=" * 80)
    print(f"üìä Final Results: {tester.tests_passed}/{tester.tests_run} tests passed")
    
    if tester.tests_passed == tester.tests_run:
        print("üéâ All authentication tests passed!")
        return 0
    else:
        print("‚ö†Ô∏è  Some authentication tests failed. Check the output above for details.")
        
        # Print failed tests summary
        failed_tests = [test for test in tester.test_results if not test['success']]
        if failed_tests:
            print("\n‚ùå Failed Tests:")
            for test in failed_tests:
                print(f"   - {test['name']}: Expected {test['expected_status']}, got {test['actual_status']}")
        
        return 1

if __name__ == "__main__":
    sys.exit(main())