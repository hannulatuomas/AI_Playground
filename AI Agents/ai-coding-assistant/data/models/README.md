# Models Directory

Place your GGUF model files here.

## Recommended Models

### For Coding Tasks:
- **CodeLlama 13B Instruct** (Q4_K_M) - Best for code generation
- **DeepSeek Coder 6.7B** (Q4_K_M) - Fast and efficient
- **Llama 3 8B Instruct** (Q4_K_M) - Good general purpose

### Where to Download:
- https://huggingface.co/TheBloke
- Search for "[Model Name]-GGUF"
- Download the Q4_K_M quantization for best balance

## File Naming:
Keep the original .gguf filename or use descriptive names:
- `codellama-13b-instruct.Q4_K_M.gguf`
- `llama-3-8b-instruct.Q4_K_M.gguf`

## Size Guidelines:
- 7-8B models: ~4-5 GB (Q4_K_M)
- 13B models: ~7-8 GB (Q4_K_M)
- Ensure you have sufficient disk space and RAM

## Note:
.gguf files are gitignored by default
