"""
AI Backend Module

Handles integration with llama.cpp for local AI inference.
"""

from .backend import AIBackend

__all__ = ["AIBackend"]
